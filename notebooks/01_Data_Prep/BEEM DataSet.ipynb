{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d92aeae-2231-4048-a56c-da4f43e77b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "INPUT_TAR = \"./beem_models_data\"\n",
    "OUTPUT_JSONL = \"promela_finetune.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "542d3af0-7ffe-494b-8a93-70f65eb06526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_beem_xml(xml_text):\n",
    "    summary = \"\"\n",
    "    instruction_parts = []\n",
    "\n",
    "    root = ET.fromstring(xml_text)\n",
    "\n",
    "    # short-description → summary\n",
    "    sd = root.find(\".//short-description\")\n",
    "    if sd is not None and sd.text:\n",
    "        summary = sd.text.strip()\n",
    "\n",
    "    # long-description → instruction\n",
    "    ld = root.find(\".//long-description\")\n",
    "    if ld is not None and ld.text:\n",
    "        instruction_parts.append(ld.text.strip())\n",
    "\n",
    "    # parameters\n",
    "    params = root.findall(\".//parameter-description\")\n",
    "    if params:\n",
    "        param_texts = []\n",
    "        for p in params:\n",
    "            if p.text:\n",
    "                param_texts.append(p.text.strip())\n",
    "        if param_texts:\n",
    "            instruction_parts.append(\n",
    "                \"Parameters:\\n\" + \"\\n\".join(param_texts)\n",
    "            )\n",
    "\n",
    "    # atomic propositions\n",
    "    aps = root.findall(\".//ap\")\n",
    "    if aps:\n",
    "        ap_list = [ap.text.strip() for ap in aps if ap.text]\n",
    "        if ap_list:\n",
    "            instruction_parts.append(\n",
    "                \"Atomic propositions:\\n\" + \", \".join(ap_list)\n",
    "            )\n",
    "\n",
    "    # properties (LTL/CTL)\n",
    "    props = root.findall(\".//property\")\n",
    "    if props:\n",
    "        prop_list = [p.text.strip() for p in props if p.text]\n",
    "        if prop_list:\n",
    "            instruction_parts.append(\n",
    "                \"Properties to verify:\\n\" + \"\\n\".join(prop_list)\n",
    "            )\n",
    "\n",
    "    instruction = \"\\n\\n\".join(instruction_parts)\n",
    "\n",
    "    return summary, instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5511460f-20f6-4aeb-a81c-7c20fa850af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding\n",
      "anderson\n",
      "at\n",
      "bakery\n",
      "blocks\n",
      "bopdp\n",
      "bridge\n",
      "brp\n",
      "brp2\n",
      "cambridge\n",
      "collision\n",
      "cyclic_scheduler\n",
      "driving_phils\n",
      "elevator\n",
      "elevator2\n",
      "elevator_planning\n",
      "exit\n",
      "extinction\n",
      "firewire_link\n",
      "firewire_tree\n",
      "fischer\n",
      "frogs\n",
      "gear\n",
      "hanoi\n",
      "iprotocol\n",
      "krebs\n",
      "lamport\n",
      "lamport_nonatomic\n",
      "lann\n",
      "leader_election\n",
      "leader_filters\n",
      "lifts\n",
      "loyd\n",
      "lup\n",
      "mcs\n",
      "msmie\n",
      "needham\n",
      "peg_solitaire\n",
      "peterson\n",
      "pgm_protocol\n",
      "phils\n",
      "plc\n",
      "pouring\n",
      "production_cell\n",
      "protocols\n",
      "public_subscribe\n",
      "reader_writer\n",
      "resistance\n",
      "rether\n",
      "rushhour\n",
      "schedule_world\n",
      "sokoban\n",
      "sorter\n",
      "synapse\n",
      "szymanski\n",
      "telephony\n",
      "train-gate\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(INPUT_TAR):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e038593-311d-4288-938b-7bacecea65e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 235 samples → beem_promela.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "BEEM_ROOT = \"beem_models_data\"          # thư mục BEEM đã giải nén\n",
    "OUTPUT_JSONL = \"beem_promela.jsonl\"\n",
    "# ============================================\n",
    "\n",
    "\n",
    "# ---------------- XML PARSER ----------------\n",
    "def parse_beem_xml(xml_path: Path):\n",
    "    summary = \"\"\n",
    "    instruction_parts = []\n",
    "\n",
    "    try:\n",
    "        root = ET.parse(xml_path).getroot()\n",
    "\n",
    "        def get_text(tag):\n",
    "            el = root.find(f\".//{tag}\")\n",
    "            return el.text.strip() if el is not None and el.text else \"\"\n",
    "\n",
    "        summary = get_text(\"short-description\")\n",
    "\n",
    "        long_desc = get_text(\"long-description\")\n",
    "        if long_desc:\n",
    "            instruction_parts.append(long_desc)\n",
    "\n",
    "        params = [p.text.strip() for p in root.findall(\".//parameter-description\") if p.text]\n",
    "        if params:\n",
    "            instruction_parts.append(\"Parameters:\\n\" + \"\\n\".join(params))\n",
    "\n",
    "        aps = [a.text.strip() for a in root.findall(\".//ap\") if a.text]\n",
    "        if aps:\n",
    "            instruction_parts.append(\"Atomic propositions:\\n\" + \", \".join(aps))\n",
    "\n",
    "        props = [p.text.strip() for p in root.findall(\".//property\") if p.text]\n",
    "        if props:\n",
    "            instruction_parts.append(\"Properties to verify:\\n\" + \"\\n\".join(props))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ XML parse error: {xml_path} ({e})\")\n",
    "\n",
    "    return summary, \"\\n\\n\".join(instruction_parts)\n",
    "\n",
    "\n",
    "# ---------------- DATASET BUILDER ----------------\n",
    "def build_dataset(beem_root: Path):\n",
    "    samples = []\n",
    "\n",
    "    for model_dir in beem_root.iterdir():\n",
    "        if not model_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        # XML\n",
    "        xml_files = list(model_dir.glob(\"*.xml\"))\n",
    "        if not xml_files:\n",
    "            continue\n",
    "\n",
    "        summary, instruction = parse_beem_xml(xml_files[0])\n",
    "\n",
    "        # PROMELA (.pm)\n",
    "        pm_files = list((model_dir / \"generated_files\").glob(\"*.pm\"))\n",
    "        if not pm_files:\n",
    "            continue\n",
    "\n",
    "        for pm in pm_files:\n",
    "            promela_code = pm.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "\n",
    "            if not promela_code:\n",
    "                continue\n",
    "\n",
    "            samples.append({\n",
    "                \"summary\": summary,\n",
    "                \"instruction\": instruction or f\"Explain and verify the Promela model for {model_dir.name}.\",\n",
    "                \"response\": promela_code\n",
    "            })\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "beem_root = Path(BEEM_ROOT)\n",
    "dataset = build_dataset(beem_root)\n",
    "\n",
    "with open(OUTPUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in dataset:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Generated {len(dataset)} samples → {OUTPUT_JSONL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec14fa6-1eb8-4808-a480-638a989f4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM_PROMT = \"\n",
    "# You are an expert in Formal Verification, Model Checking, and PROMELA/SPIN.\n",
    "\n",
    "# Your task is to transform a natural language software specification into a\n",
    "# formally correct PROMELA model using a rigorous, multi-stage methodology.\n",
    "\n",
    "# You MUST follow all stages below in order.\n",
    "# Do NOT skip stages.\n",
    "# Use precise formal reasoning and bounded state modeling.\n",
    "# STAGE 1 – Specification Analysis\n",
    "\n",
    "# From the natural language specification:\n",
    "\n",
    "# 1. Identify ACTORS (entities that perform actions).\n",
    "#    - Map each actor to a PROMELA proctype or active proctype.\n",
    "\n",
    "# 2. Identify DATA ENTITIES:\n",
    "#    - Shared data → global variables or channels.\n",
    "#    - Local data → local variables inside proctype.\n",
    "#    - Specify type: bool, byte, int, mtype, chan.\n",
    "\n",
    "# 3. Identify STATE DESCRIPTORS:\n",
    "#    - Adjectives or phrases describing states\n",
    "#      (e.g., RED, GREEN, WAITING, LOCKED).\n",
    "#    - Collect them as the candidate state set S.\n",
    "\n",
    "# Output this stage as structured lists.\n",
    "# STAGE 2 – State Modeling\n",
    "\n",
    "# 1. Identify STATE VARIABLES:\n",
    "#    - Variables that define the global or local system state.\n",
    "#    - Specify initial values.\n",
    "\n",
    "# 2. Define the STATE SPACE:\n",
    "#    - Enumerate all valid values of state variables.\n",
    "#    - Use mtype enumerations to bound the state space.\n",
    "\n",
    "# 3. For each process:\n",
    "#    - Define its control states (FSM states).\n",
    "#    - Assign symbolic names (e.g., IDLE, GREEN, YELLOW, RED).\n",
    "\n",
    "# Output:\n",
    "# - State variables and domains\n",
    "# - Control states per process\n",
    "\n",
    "# STAGE 3 – Transition Logic\n",
    "\n",
    "# 1. Identify EVENTS:\n",
    "#    - Actions that trigger transitions\n",
    "#      (e.g., timeout, button press, message receive).\n",
    "\n",
    "# 2. Identify GUARDS:\n",
    "#    - Conditions required for transitions.\n",
    "#    - Express as boolean expressions.\n",
    "\n",
    "# 3. Construct STATE TRANSITION TABLES:\n",
    "#    For each process, list transitions in the form:\n",
    "#    (Current State, Guard, Action, Next State)\n",
    "\n",
    "# 4. Ensure:\n",
    "#    - Deterministic or nondeterministic behavior is explicit.\n",
    "#    - No implicit transitions.\n",
    "\n",
    "# STAGE 4 – PROMELA Mapping\n",
    "\n",
    "# 1. Translate each process FSM into PROMELA:\n",
    "#    - Use do..od loops.\n",
    "#    - Use :: guard -> action syntax.\n",
    "#    - Represent states using mtype or explicit labels.\n",
    "\n",
    "# 2. Use atomic or d_step:\n",
    "#    - Only for logically indivisible transitions.\n",
    "#    - To reduce state explosion where appropriate.\n",
    "\n",
    "# 3. Define:\n",
    "#    - Global variables\n",
    "#    - Channels (if any)\n",
    "#    - init process to start the system\n",
    "\n",
    "# STAGE 5 – Verification\n",
    "\n",
    "# 1. Identify SAFETY PROPERTIES:\n",
    "#    - Conditions that must NEVER be violated\n",
    "#      (e.g., never two conflicting traffic lights are GREEN).\n",
    "\n",
    "# 2. Express each property as an LTL formula.\n",
    "\n",
    "# 3. Optionally define:\n",
    "#    - Monitor processes\n",
    "#    - Assertions\n",
    "\n",
    "# OUTPUT STRUCTURE (STRICT):\n",
    "\n",
    "# STEP 1 – Global Variables, Channels, and Processes\n",
    "# STEP 2 – State Space and Domains\n",
    "# STEP 3 – Process FSM Descriptions\n",
    "# STEP 4 – State Transition Tables\n",
    "# STEP 5 – Safety Properties and LTL Formulas\n",
    "# STEP 6 – Complete PROMELA Code\n",
    "\n",
    "# The final PROMELA code must be:\n",
    "# - Syntactically correct\n",
    "# - Directly compilable by SPIN\n",
    "# - Faithful to the original specification\n",
    "# \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad829f6e-ed59-456c-92e8-9899c6788962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== CONFIG =====\n",
    "INPUT_DIR = \"beem_promela.jsonl\"          # thư mục chứa file BEEM đã parse\n",
    "OUTPUT_FILE = \"beem_promela_finetune.jsonl\"  # file output\n",
    "MAX_CODE_CHARS = 20000           # optional, có thể bỏ nếu muốn\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert in Formal Verification, Model Checking, and PROMELA/SPIN.\n",
    "\n",
    "Internally apply a rigorous multi-stage methodology:\n",
    "- Specification analysis and entity extraction\n",
    "- State variable identification\n",
    "- Finite-state modeling\n",
    "- Transition table construction\n",
    "- PROMELA mapping\n",
    "- Safety verification using LTL\n",
    "\n",
    "These stages are INTERNAL and MUST NOT be included in the output.\n",
    "\n",
    "ONLY output valid, compilable PROMELA code.\n",
    "Do NOT include explanations or stage descriptions, Do NOT use FSM, state, transition tables, or pseudo-code..\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c24e4d-4649-44a7-a255-9c9e69deb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_beem_sample(data):\n",
    "    instruction = data.get(\"instruction\", \"\").strip()\n",
    "    response = data.get(\"response\", \"\").strip()\n",
    "\n",
    "    if not instruction or not response:\n",
    "        return None\n",
    "\n",
    "    if MAX_CODE_CHARS and len(response) > MAX_CODE_CHARS:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": instruction\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            }\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0082698-2df5-42fa-97c4-f671b3ed0c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:00, 11314.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DONE\n",
      "✔ Valid samples : 228\n",
      "✖ Skipped       : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== CONFIG =====\n",
    "INPUT_JSONL = \"beem_promela.jsonl\"   # file JSONL đầu vào\n",
    "OUTPUT_FILE = \"beem_promela_finetune.jsonl\"    # file output\n",
    "MAX_CODE_CHARS = 20000             # optional\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert in Formal Verification, Model Checking, and PROMELA/SPIN.\n",
    "\n",
    "Internally apply a rigorous multi-stage methodology:\n",
    "- Specification analysis and entity extraction\n",
    "- State variable identification\n",
    "- Finite-state modeling\n",
    "- Transition table construction\n",
    "- PROMELA mapping\n",
    "- Safety verification using LTL\n",
    "\n",
    "These stages are INTERNAL and MUST NOT be included in the output.\n",
    "\n",
    "ONLY output valid, compilable PROMELA code.\n",
    "Do NOT include explanations or stage descriptions, Do NOT use FSM, state, transition tables, or pseudo-code..\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def convert_beem_sample(data):\n",
    "    instruction = data.get(\"instruction\", \"\").strip()\n",
    "    response = data.get(\"response\", \"\").strip()\n",
    "\n",
    "    if not instruction or not response:\n",
    "        return None\n",
    "\n",
    "    if MAX_CODE_CHARS and len(response) > MAX_CODE_CHARS:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": instruction\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    valid, skipped = 0, 0\n",
    "\n",
    "    with open(INPUT_JSONL, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        for line in tqdm(fin):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                sample = convert_beem_sample(data)\n",
    "\n",
    "                if sample is None:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                fout.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "                valid += 1\n",
    "\n",
    "            except Exception:\n",
    "                skipped += 1\n",
    "\n",
    "    print(\"✅ DONE\")\n",
    "    print(f\"✔ Valid samples : {valid}\")\n",
    "    print(f\"✖ Skipped       : {skipped}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fbed0-08d5-4a23-8467-2a14fb1e0848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
