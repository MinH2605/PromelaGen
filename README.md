
# NghiÃªn cá»©u á»©ng dá»¥ng ká»¹ thuáº­t Fine-tuning vÃ  RAG trÃªn LLM Ä‘á»ƒ tá»± Ä‘á»™ng sinh Promela

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Transformers-yellow?style=for-the-badge)](https://huggingface.co/)
[![LangChain](https://img.shields.io/badge/ðŸ¦œðŸ”—%20LangChain-RAG-green?style=for-the-badge)](https://python.langchain.com/)
[![SPIN Verifier](https://img.shields.io/badge/Tool-SPIN_Verifier-red?style=for-the-badge)](https://spinroot.com/)

>
> **Äá» tÃ i:** Tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh sinh mÃ£ kiá»ƒm chá»©ng **Promela** (Process Meta Language) tá»« mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn. Dá»± Ã¡n káº¿t há»£p ká»¹ thuáº­t **Fine-tuning** (QLoRA) trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n vÃ  **RAG** (Retrieval-Augmented Generation) Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh cÃº phÃ¡p chÃ­nh xÃ¡c, Ä‘á»“ng thá»i tÃ­ch há»£p cÆ¡ cháº¿ **Self-Correction** (tá»± sá»­a lá»—i) dá»±a trÃªn pháº£n há»“i cá»§a trÃ¬nh biÃªn dá»‹ch SPIN.

---

## ðŸ‘¥ NhÃ³m tÃ¡c giáº£ (Authors)

| STT | ThÃ nh viÃªn | MÃ£ há»c viÃªn | Vai trÃ² & ÄÃ³ng gÃ³p chÃ­nh |
|:---:|------------|:-----------:|--------------------------|
| 1 | **Nguyá»…n Äá»©c Minh** | 20252092M | Thiáº¿t káº¿ kiáº¿n trÃºc há»‡ thá»‘ng, Tiá»n xá»­ lÃ½ dá»¯ liá»‡u, Training Model, TÃ­ch há»£p RAG & SPIN Verifier |
| 2 | **Pháº¡m VÄƒn Quang** | 20251045M | Lá»±a chá»n Model ná»n, Training Model, XÃ¢y dá»±ng vÃ  tá»‘i Æ°u RAG Pipeline |
| 3 | **Tráº§n Äá»©c Duy** | 20251049M | Training Model, NghiÃªn cá»©u Dataset BEEM, PhÃ¡t triá»ƒn cÆ¡ cháº¿ sá»­a lá»—i (Self-Correction Loop) |

**Giáº£ng viÃªn hÆ°á»›ng dáº«n:** TS. Tráº§n Nháº­t HÃ³a

---

## ðŸ“‚ Cáº¥u trÃºc Repository (Project Structure)

Äá»ƒ dá»± Ã¡n hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh, mÃ£ nguá»“n Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ¡c thÆ° má»¥c chá»©c nÄƒng nhÆ° sau:

```text
promela-llm-generation/
â”‚
â”œâ”€â”€ data/                       # Quáº£n lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ beem_models_data/       # (Input) ThÆ° má»¥c chá»©a dá»¯ liá»‡u gá»‘c BEEM (XML/PML)
â”‚   â””â”€â”€ promela_finetune.jsonl  # (Output) Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch Ä‘á»ƒ Fine-tune
â”‚
â”œâ”€â”€ notebooks/                  # MÃ£ nguá»“n (Jupyter Notebooks)
â”‚   â”œâ”€â”€ 01_Data_Prep/
â”‚   â”‚   â”œâ”€â”€ BEEM_DataSet.ipynb  # TrÃ­ch xuáº¥t dá»¯ liá»‡u, convert XML -> JSONL
â”‚   â”‚   â””â”€â”€ CheckFileData.ipynb # Kiá»ƒm tra thá»‘ng kÃª token vÃ  Ä‘á»‹nh dáº¡ng file
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_Training/
â”‚   â”‚   â””â”€â”€ FineTunning_LLM.ipynb # Huáº¥n luyá»‡n LLM vá»›i QLoRA/PEFT
â”‚   â”‚
â”‚   â”œâ”€â”€ 03_RAG_Core/
â”‚   â”‚   â””â”€â”€ RAG_LangChain.ipynb   # XÃ¢y dá»±ng Vector DB vÃ  RAG Pipeline
â”‚   â”‚
â”‚   â””â”€â”€ 04_Inference_Verify/
â”‚       â”œâ”€â”€ Inference.ipynb       # Cháº¡y sinh mÃ£ thá»­ nghiá»‡m (Demo)
â”‚       â””â”€â”€ Promela_Code.ipynb    # Pipeline chÃ­nh: Sinh mÃ£ -> Cháº¡y SPIN -> Sá»­a lá»—i
â”‚
â”œâ”€â”€ requirements.txt            # Danh sÃ¡ch thÆ° viá»‡n Python cáº§n thiáº¿t
â””â”€â”€ README.md                   # TÃ i liá»‡u hÆ°á»›ng dáº«n nÃ y
