
# NghiÃªn cá»©u á»©ng dá»¥ng ká»¹ thuáº­t Fine-tuning vÃ  RAG trÃªn LLM Ä‘á»ƒ tá»± Ä‘á»™ng sinh Promela

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Transformers-yellow?style=for-the-badge)](https://huggingface.co/)
[![LangChain](https://img.shields.io/badge/ðŸ¦œðŸ”—%20LangChain-RAG-green?style=for-the-badge)](https://python.langchain.com/)
[![SPIN Verifier](https://img.shields.io/badge/Tool-SPIN_Verifier-red?style=for-the-badge)](https://spinroot.com/)

>
> **Äá» tÃ i:** Tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh sinh mÃ£ kiá»ƒm chá»©ng **Promela** (Process Meta Language) tá»« mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn. Dá»± Ã¡n káº¿t há»£p ká»¹ thuáº­t **Fine-tuning** (QLoRA) trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n vÃ  **RAG** (Retrieval-Augmented Generation) Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh cÃº phÃ¡p chÃ­nh xÃ¡c, Ä‘á»“ng thá»i tÃ­ch há»£p cÆ¡ cháº¿ **Self-Correction** (tá»± sá»­a lá»—i) dá»±a trÃªn pháº£n há»“i cá»§a trÃ¬nh biÃªn dá»‹ch SPIN.

---

## ðŸ‘¥ NhÃ³m tÃ¡c giáº£ (Authors)

| STT | ThÃ nh viÃªn | MÃ£ há»c viÃªn | Vai trÃ² & ÄÃ³ng gÃ³p chÃ­nh |
|:---:|------------|:-----------:|--------------------------|
| 1 | **Nguyá»…n Äá»©c Minh** | 20252092M | Thiáº¿t káº¿ kiáº¿n trÃºc há»‡ thá»‘ng, Tiá»n xá»­ lÃ½ dá»¯ liá»‡u, Training Model, TÃ­ch há»£p RAG & SPIN Verifier |
| 2 | **Pháº¡m VÄƒn Quang** | 20251045M | Lá»±a chá»n Model ná»n, Training Model, XÃ¢y dá»±ng vÃ  tá»‘i Æ°u RAG Pipeline |
| 3 | **Tráº§n Äá»©c Duy** | 20251049M | Training Model, NghiÃªn cá»©u Dataset BEEM, PhÃ¡t triá»ƒn cÆ¡ cháº¿ sá»­a lá»—i (Self-Correction Loop) |

**Giáº£ng viÃªn hÆ°á»›ng dáº«n:** TS. Tráº§n Nháº­t HÃ³a

---

## ðŸ“‚ Cáº¥u trÃºc Repository (Project Structure)

Äá»ƒ dá»± Ã¡n hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh, mÃ£ nguá»“n Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ¡c thÆ° má»¥c chá»©c nÄƒng nhÆ° sau:

```text
promela-llm-generation/
â”‚
â”œâ”€â”€ data/                       # Quáº£n lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ beem_models_data/       # (Input) ThÆ° má»¥c chá»©a dá»¯ liá»‡u gá»‘c BEEM (XML/PML)
â”‚   â””â”€â”€ promela_finetune.jsonl  # (Output) Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch Ä‘á»ƒ Fine-tune
â”‚
â”œâ”€â”€ notebooks/                  # MÃ£ nguá»“n (Jupyter Notebooks)
â”‚   â”œâ”€â”€ 01_Data_Prep/
â”‚   â”‚   â”œâ”€â”€ BEEM_DataSet.ipynb  # TrÃ­ch xuáº¥t dá»¯ liá»‡u, convert XML -> JSONL
â”‚   â”‚   â”œâ”€â”€  Promela_Code.ipynb  # Sinh mÃ´ táº£ cho Ä‘oáº¡n mÃ£ Promela vá»›i cÃ¡c code dá»¯ liá»‡u Stack V2
â”‚   â”‚   â””â”€â”€ CheckFileData.ipynb # Kiá»ƒm tra thá»‘ng kÃª token vÃ  Ä‘á»‹nh dáº¡ng file
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_Training/
â”‚   â”‚   â””â”€â”€ FineTunning_LLM.ipynb # Huáº¥n luyá»‡n LLM vá»›i QLoRA/PEFT (GPT-OSS:20b)
â”‚   â”‚
â”‚   â”œâ”€â”€ 03_RAG_Core/
â”‚   â”‚   â””â”€â”€ RAG_LangChain.ipynb   # XÃ¢y dá»±ng Vector DB vÃ  RAG Pipeline
â”‚   â”‚
â”‚   â””â”€â”€ 04_Inference_Verify/
â”‚       â””â”€â”€ Inference.ipynb       # Cháº¡y sinh mÃ£ thá»­ nghiá»‡m (Demo)
â”‚                                 # Pipeline chÃ­nh: Sinh mÃ£ -> Cháº¡y SPIN -> Sá»­a lá»—i
â”œâ”€â”€ requirements.txt            # Danh sÃ¡ch thÆ° viá»‡n Python cáº§n thiáº¿t
â””â”€â”€ README.md                   # TÃ i liá»‡u hÆ°á»›ng dáº«n nÃ y
```
---

## ðŸ› ï¸ YÃªu cáº§u há»‡ thá»‘ng & CÃ i Ä‘áº·t (Installation)



**1. YÃªu cáº§u pháº§n cá»©ng & CÃ´ng cá»¥**
- Python: PhiÃªn báº£n 3.10 trá»Ÿ lÃªn.

- GPU: Khuyáº¿n nghá»‹ NVIDIA GPU (VRAM >= 16GB) Ä‘á»ƒ cháº¡y Fine-tuning vÃ  Load Model 4-bit.

- SPIN Model Checker: Báº¯t buá»™c cÃ i Ä‘áº·t Ä‘á»ƒ cháº¡y module kiá»ƒm lá»—i.

- Linux (Debian/Ubuntu): sudo apt-get install spin

- MacOS/Windows: Táº£i vÃ  biÃªn dá»‹ch tá»« SpinRoot.

- Ollama: Cáº§n thiáº¿t náº¿u cháº¡y Inference Local trong Promela_Code.ipynb. Táº£i táº¡i ollama.com.

**2. CÃ i Ä‘áº·t thÆ° viá»‡n Python**
Cháº¡y lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t cÃ¡c gÃ³i phá»¥ thuá»™c:

```Bash

pip install -r requirements.txt
```
(Ná»™i dung file requirements.txt Ä‘Æ°á»£c cung cáº¥p trong repo nÃ y)

## ðŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng (Usage Workflow)

<img width="1381" height="769" alt="Tiá»ƒu luáº­n Promela drawio" src="https://github.com/user-attachments/assets/76cae5af-c8db-4549-87d7-0a11ea373818" />

**BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u**
- Cháº¡y notebook notebooks/01_Data_Prep/BEEM_DataSet.ipynb.

+ Input: Dá»¯ liá»‡u thÃ´ tá»« thÆ° má»¥c data/beem_models_data/.

+ Process: Script sáº½ trÃ­ch xuáº¥t cáº·p <Instruction, Promela Code> tá»« file XML.

+ Output: File data/promela_finetune.jsonl.

**BÆ°á»›c 2: Huáº¥n luyá»‡n mÃ´ hÃ¬nh (Fine-tuning)**
- Cháº¡y notebook notebooks/02_Training/FineTunning_LLM.ipynb.

- Load model ná»n (DeepSeek-Coder hoáº·c CodeLlama).

- Thá»±c hiá»‡n Fine-tuning vá»›i cáº¥u hÃ¬nh QLoRA (Quantized Low-Rank Adaptation).

- LÆ°u Adapter Weights vÃ o thÆ° má»¥c output.

**BÆ°á»›c 3: Khá»Ÿi táº¡o RAG (Retrieval)**
- Sá»­ dá»¥ng notebooks/03_RAG_Core/RAG_LangChain.ipynb.

- Há»‡ thá»‘ng sáº½ Ä‘á»c tÃ i liá»‡u hÆ°á»›ng dáº«n Promela chuáº©n.

- Táº¡o Vector Database (sá»­ dá»¥ng ChromaDB) Ä‘á»ƒ lÆ°u trá»¯ kiáº¿n thá»©c cÃº phÃ¡p.

**BÆ°á»›c 4: Cháº¡y sinh mÃ£ & Tá»± sá»­a lá»—i (Inference Loop)**

- Cháº¡y notebook notebooks/04_Inference_Verify/Promela_Code.ipynb.

- ÄÃ¢y lÃ  quy trÃ¬nh khÃ©p kÃ­n quan trá»ng nháº¥t cá»§a dá»± Ã¡n:

+ User Input: Nháº­p mÃ´ táº£ há»‡ thá»‘ng cáº§n kiá»ƒm chá»©ng.

+ Generation: LLM sinh mÃ£ ban Ä‘áº§u.
  
+ Verification: Gá»i lá»‡nh há»‡ thá»‘ng spin -a output.pml.
  
+ RAG: TÃ¬m kiáº¿m cÃº phÃ¡p Promela liÃªn quan.

+ Correction: Náº¿u SPIN bÃ¡o lá»—i (Syntax/Compile error), lá»—i sáº½ Ä‘Æ°á»£c gá»­i láº¡i vÃ o LLM Ä‘á»ƒ sinh láº¡i mÃ£ má»›i tá»‘i Æ°u hÆ¡n.

## ðŸ“Š PhÆ°Æ¡ng phÃ¡p & Káº¿t quáº£ (Methodology)
- Dá»± Ã¡n giáº£i quyáº¿t váº¥n Ä‘á» khan hiáº¿m dá»¯ liá»‡u Promela vÃ  Ä‘á»™ phá»©c táº¡p cá»§a cÃº phÃ¡p báº±ng kiáº¿n trÃºc:

+ Fine-tuning: GiÃºp Model há»c Ä‘Æ°á»£c cáº¥u trÃºc Ä‘áº·c thÃ¹ cá»§a ngÃ´n ngá»¯ Promela (channels, process types, atomic sequences).

+ RAG: Giáº£m thiá»ƒu "áº£o giÃ¡c" (hallucination) báº±ng cÃ¡ch cung cáº¥p tra cá»©u thá»i gian thá»±c vÃ o tÃ i liá»‡u chuáº©n.

+ Self-Correction: Tá»± Ä‘á»™ng sá»­a cÃ¡c lá»—i biÃªn dá»‹ch cÆ¡ báº£n mÃ  khÃ´ng cáº§n con ngÆ°á»i can thiá»‡p.

=> Káº¿t quáº£: Há»‡ thá»‘ng giáº£m Ä‘Ã¡ng ká»ƒ tá»· lá»‡ lá»—i cÃº phÃ¡p so vá»›i Zero-shot prompting vÃ  cÃ³ kháº£ nÄƒng sinh Ä‘Æ°á»£c cÃ¡c Ä‘oáº¡n mÃ£ phá»©c táº¡p nhÆ° giao thá»©c máº¡ng, há»‡ thá»‘ng phÃ¢n tÃ¡n.
